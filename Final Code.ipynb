{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ad6f50-4c1b-4895-8cc2-29eec44a2f82",
   "metadata": {},
   "source": [
    "# Download Dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b6b03-7b3f-4084-8222-3dfe3c3f2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"raj713335/tbo-hotels-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13c070-96a7-4cfb-b055-41023ed5820e",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6376789-4b4e-44da-91de-bca5a51c532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda12x\n",
    "# !pip install cuml-cu12==24.12.0\n",
    "!pip install --upgrade pip\n",
    "!pip install lightgbm\n",
    "!pip install nltk\n",
    "# needed only if using colab GPU version\n",
    "# !mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a7fd1-8b86-4dc3-a968-48fcbc5043b6",
   "metadata": {},
   "source": [
    "# Import all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd30e4a-3690-4552-b3e4-e681852ba7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report,r2_score,mean_squared_error,accuracy_score,confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from scipy.sparse import issparse,hstack,csr_matrix\n",
    "\n",
    "# from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from joblib import Memory\n",
    "from joblib import Parallel,delayed\n",
    "memory = Memory(location='./cache', verbose=0)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb8d0f-ee18-467d-95b4-9948c2135f46",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8bb35-1454-40d3-8a4f-4ef911057d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hotels.csv\", encoding='ISO-8859-1')\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.drop(columns=['Map','countyCode','cityCode','HotelCode','PhoneNumber','FaxNumber','PinCode'])\n",
    "# df = df.drop(columns=['Map','HotelName','countyCode','cityCode','HotelCode','Address','HotelWebsiteUrl','PhoneNumber','FaxNumber','PinCode'])\n",
    "\n",
    "\n",
    "# df[(df.Attractions.isnull())&(df.Description.isnull())&(df.HotelFacilities.isnull())].all(axis=1).sum()\n",
    "\n",
    "cols_to_check = ['Attractions','Description','HotelFacilities','HotelName','Address','HotelWebsiteUrl']\n",
    "# cols_to_check = ['Attractions','Description','HotelFacilities']\n",
    "df = df[~df[cols_to_check].isnull().all(axis=1)]\n",
    "\n",
    "df['Attractions'] = df['Attractions'].fillna(df['Attractions'].mode()[0])\n",
    "df['Description'] = df['Description'] = df['Description'].fillna(df['Description'].mode()[0])\n",
    "df['HotelFacilities'] = df['HotelFacilities'].fillna(df['HotelFacilities'].mode()[0])\n",
    "df['HotelName'] = df['HotelName'].fillna(df['HotelName'].mode()[0])\n",
    "df['Address'] = df['Address'].fillna(df['Address'].mode()[0])\n",
    "df['HotelWebsiteUrl'] = df['HotelWebsiteUrl'].fillna(df['HotelWebsiteUrl'].mode()[0])\n",
    "\n",
    "text_cols = ['Attractions','Description','HotelFacilities','HotelName','Address','HotelWebsiteUrl']\n",
    "# text_cols = ['Attractions','Description','HotelFacilities']\n",
    "categorical_cols = ['countyName','cityName']\n",
    "\n",
    "target_map = {'FourStar':4,'FiveStar':5,'ThreeStar':3,'TwoStar':2,'OneStar':1,'All':5}\n",
    "df['HotelRating'] = df['HotelRating'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64a8bf-1cbb-4148-aa74-6d7c9a35b7d3",
   "metadata": {},
   "source": [
    "# Declare text operation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ef647-ed35-4ae4-b566-8e99a0bfcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def combine_row(row):\n",
    "    \"\"\"Combine the values of a row into a single space-separated string.\"\"\"\n",
    "    return \" \".join(row.astype(str))\n",
    "\n",
    "def join_text_columns(X):\n",
    "    \"\"\"\n",
    "    Combine multiple text columns into a single column.\n",
    "    Returns a 2D DataFrame with one column.\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        joined = X.apply(combine_row, axis=1)\n",
    "        return joined.to_frame()  # Ensure 2D output\n",
    "    else:\n",
    "        return np.array([combine_row(row) for row in X]).reshape(-1, 1)\n",
    "\n",
    "def flatten_array(x):\n",
    "    \"\"\"Flatten a 2D array to a 1D array.\"\"\"\n",
    "    return x.ravel()\n",
    "\n",
    "\n",
    "def remove_nan(X):\n",
    "    if hasattr(X, 'dropna'):\n",
    "        return X.dropna()\n",
    "    elif issparse(X):\n",
    "        return X\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "nan_remover = FunctionTransformer(remove_nan, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b63d5-1d94-4ea3-b31e-9e7846477432",
   "metadata": {},
   "source": [
    "# Vectorize the Data and Save it to pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0392c25-6f91-479d-b0cc-2601cd2b08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['HotelRating'])\n",
    "y = df['HotelRating']\n",
    "del df\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by tokenizing, lemmatizing, and removing stopwords.\"\"\"\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "@memory.cache\n",
    "def preprocess_texts_parallel(text_list,n_jobs=-1):\n",
    "    \"\"\"Apply preprocess_text to each element in the list.\"\"\"\n",
    "    return Parallel(n_jobs=n_jobs,verbose=10)(\n",
    "        delayed(preprocess_text)(text)for text in text_list\n",
    "    )\n",
    "\n",
    "text_data = join_text_columns(x[text_cols])\n",
    "text_data.fillna(\"\", inplace=True)\n",
    "text_data_flat = text_data.values.ravel()\n",
    "\n",
    "processed_texts = preprocess_texts_parallel(text_data_flat,n_jobs=-1)\n",
    "process_texts_series = pd.Series(processed_texts)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "x_text = tfidf_vectorizer.fit_transform(process_texts_series)\n",
    "\n",
    "x_cat = x[categorical_cols].copy()\n",
    "for col in categorical_cols:\n",
    "    x_cat[col] = x_cat[col].fillna(x_cat[col].mode()[0])\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "x_cat = onehot_encoder.fit_transform(x_cat)\n",
    "x_cat_sparse = csr_matrix(x_cat)\n",
    "x_final = hstack([x_text, x_cat_sparse])\n",
    "print(type(x_final))\n",
    "print(x_final.shape)\n",
    "import joblib\n",
    "\n",
    "# Save the processed feature matrix and labels\n",
    "joblib.dump(x_final, 'x_final.pkl')\n",
    "joblib.dump(y, 'y.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(onehot_encoder, 'onehot_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22864f-23db-4793-a190-62fb7ed5a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(onehot_encoder, 'onehot_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736d343-4041-494f-8502-eef70aa598b7",
   "metadata": {},
   "source": [
    "# Load the feature matrix if it was unloaded from the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cab62d-dd3e-44e9-b036-4d84a7986c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = joblib.load('x_final.pkl')\n",
    "y = joblib.load('y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d450e08-15b5-4d8a-b978-2e430d1b2608",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40fd7a-61f1-4330-8776-2243f56b7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_final, y, test_size=0.2, random_state=12)\n",
    "del x_final,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db26de4-c116-4c10-ba49-44a132680777",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c27777-68fd-4ea6-9aad-3ebb67bb0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(random_state=42,\n",
    "                       force_col_wise=True,\n",
    "                       n_jobs=-1,\n",
    "                       # device='gpu',\n",
    "                       # gpu_platform_id=0,\n",
    "                       # gpu_device_id=0,\n",
    "                       max_bin=512,\n",
    "                       #boosting_type=\"rf\",\n",
    "                       num_leaves=175,\n",
    "                       learning_rate=0.1,\n",
    "                       n_estimators=200\n",
    "                      )\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004629b0-29de-4f08-a577-6166ccae1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8c846-338f-4827-a5d9-3eac46a642fd",
   "metadata": {},
   "source": [
    "## Note if you have memory issues then these are the functions/variables which we do not need now so you can remove them from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d33c9f-c36c-4610-9720-0b6c26cd0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "del RandomizedSearchCV, SimpleImputer, TfidfVectorizer, WordNetLemmatizer, hstack,issparse, lemmatizer, memory, nltk, stop_words,stopwords,word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497eb243-ee7a-4e3b-a50d-ffa3f248b649",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ef07a-1062-4c7a-a1e4-15a78b4420be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd8ce7-7396-4496-8cd9-2c4068661d15",
   "metadata": {},
   "source": [
    "# Check Accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb807959-1d60-41c3-b743-b2fea3e41a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb3ad5-8d22-4194-80f7-8f01828d570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=[1,2,3,4,5],\n",
    "            yticklabels=[1,2,3,4,5]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49624ca3-e23c-4e54-ac7c-4c25c94d7bcc",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c59d99-cb5c-4a3d-8672-0e059c9ad8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using joblib\n",
    "joblib.dump(model, 'hotel_rating_pipeline_cpu.joblib')\n",
    "# Save the model using pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
